% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/pda.R
\name{pda}
\alias{pda}
\title{Pattern recognition with PLS+LDA}
\usage{
pda(y, X, prior = NULL, max.dim = NULL, selected = NULL)
}
\arguments{
\item{y}{Vector of responses, must be a factor with exactly 2 levels. See \code{\link{mpda}}
for multi-level problems.}

\item{X}{Numeric matrix of predictor values.}

\item{prior}{Vector of prior probabilities, one value for each factor level in \code{y}.}

\item{max.dim}{Integer, the maximum number of dimensions to consider in PLS.}

\item{selected}{Vector of logicals, indicating a variable selection, see below.}
}
\value{
A \code{pda} object, which is a list with elements \code{PLS}, \code{LDA}, \code{Response} and
\code{Selected}. The
element \code{PLS} is simply the object returned from \code{\link{plsr}}. The element \code{LDA} is a
list with the fitted \code{lda} objects for each dimension. The elements \code{Response} and \code{Selected}
are copies of the arguments \code{y} and \code{selected}.
}
\description{
A classification method that uses first PLS for dimension-reduction
and then LDA in the truncated score-space.
}
\details{
This classification method is designed for highly multivariate problems, i.e. where the
predictor matrix \code{X} has many and/or highly correlated columns (variables).

First, the response factor is dummy-coded as 0's and 1's. This vector is then used together
with \code{X} to fit a PLS-model using the \code{oscorespls} algorithm, see the \code{\link{plsr}}
for details. The idea is that PLS will find linear combinations, denoted PLS-components, of the
original variables to be as an orthogonal basis for spanning the predictor space in such a way that objects
from the two factor levels are separated as much as possible. The score-matrix from this step are the original
data objects transformed into this subspace.

Next, the score-matrix is truncated, i.e. only \code{max.dim} dimensions are used. The PLS-components
are all ordered such that the first component has the largest linear discriminative power. Thus, only a small
subspace is usually needed for separating between the two classes. This truncated score-matrix is used
as the predictor-matrix in LDA. One LDA-model is fitted for each dimension 1,...,\code{max.dim},
see \code{\link{lda}} for details.

The predictor matrix \code{X} is centered, but not scaled. If you want scaled variables you need to do this
(with \code{\link{scale}}) before you call \code{pda}.

The argument \code{selected} may be used to select a subset of the predictor variables (columns of \code{X}),
e.g. after a variable selection (see \code{\link{eliminator}}). This must be a
vector of logicals (\code{TRUE/FALSE}) indicating the selected variables, and the reduced predictor
matrix becomes \code{X[,which(selected)]}. The main reason for this option is the use of \code{\link{pda}}
in \code{\link{mpda}}.
}
\examples{
data(microbiome)
y <- microbiome[1:40,1]
X <- as.matrix(microbiome[1:40,-1])
m.trn <- pda(y,X,prior=c(0.5,0.5),max.dim=10)

data(poems)
y <- factor(poems[11:28,1],levels=c("Blake","Eliot"))
X <- as.matrix(poems[11:28,-1])
selection <- rep(FALSE,ncol(X))
selection[c(1,5,9,15,21)] <- TRUE   # using letters a, e, i, o and u only
p.trn <- pda(y,X,prior=c(1,1),selected=selection)

}
\seealso{
\code{\link{predict.pda}}, \code{\link{pdaDim}}.
}
\author{
Lars Snipen.
}
